{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOo2qPdx/oeEgNQ84IZn/yL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hydrationn/Machine-DeepLearning/blob/main/DeepLearning/lab/20240418_%EC%8B%A4%EC%8A%B503_Regularization_and_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice 1. Dropout"
      ],
      "metadata": {
        "id": "m0USCP11ckWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xa3WFMwXcWBe"
      },
      "outputs": [],
      "source": [
        "# import package\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.utils.data as data_utils\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU/CPU setting\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzUW-mpLcYr2",
        "outputId": "47c98f97-120a-4c2f-c8dd-420ca13cf5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dataset\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrdAKYNJcaoO",
        "outputId": "8610bb2b-32c1-4241-c38d-6f5eae0a6c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 95853772.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 84356332.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 30045448.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5772887.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch generation\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "yHcx9cfIcrQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "\n",
        "class MLP_Dropout(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MLP_Dropout, self).__init__()\n",
        "    self.fc1 = nn.Linear(784, 256)\n",
        "    self.fc2 = nn.Linear(256, 64)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "    self.dp1 = nn.Dropout(p=0.4)\n",
        "    self.dp2 = nn.Dropout(p = 0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h1 = F.relu(self.fc1(x))\n",
        "    h1dp = self.dp1(h1)\n",
        "    h2 = F.relu(self.fc2(h1dp))\n",
        "    h2dp = self.dp2(h2)\n",
        "    output = self.fc3(h2dp)\n",
        "    return output"
      ],
      "metadata": {
        "id": "uYP3sue9dDFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter, model, loss function, optimizer\n",
        "\n",
        "# 파라미터, 모델 정의\n",
        "num_epochs = 10\n",
        "learning_rate = 0.01\n",
        "\n",
        "model = MLP_Dropout().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "ya3geOFId65p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "\n",
        "# Model Train\n",
        "loss_list = []\n",
        "for epoch_num in range(num_epochs):\n",
        "  average_cost = 0\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx, (x_data, y_label) in enumerate(train_loader):\n",
        "    num_of_mini_batch = len(train_loader)\n",
        "\n",
        "    x_data = x_data.reshape(-1, 28*28)\n",
        "    input_image = x_data.to(device)\n",
        "    label = y_label.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    y_predict = model(input_image)\n",
        "    loss = criterion(y_predict, label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    average_cost = average_cost + (loss.item()/num_of_mini_batch)\n",
        "    loss_list.append(loss)\n",
        "\n",
        "  print(\"Epoch {} Loss {:.5f}\".format((epoch_num+1), average_cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq_XpgAdef9I",
        "outputId": "5c16828b-732b-4f5b-d9d7-72dc766a7b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss 0.36812\n",
            "Epoch 2 Loss 0.27414\n",
            "Epoch 3 Loss 0.24278\n",
            "Epoch 4 Loss 0.23866\n",
            "Epoch 5 Loss 0.22997\n",
            "Epoch 6 Loss 0.21457\n",
            "Epoch 7 Loss 0.20419\n",
            "Epoch 8 Loss 0.21019\n",
            "Epoch 9 Loss 0.20264\n",
            "Epoch 10 Loss 0.21395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation\n",
        "\n",
        "with torch.no_grad():\n",
        "  num_total_data = 0\n",
        "  correct = 0\n",
        "  model.eval()\n",
        "  for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "\n",
        "    images = images.reshape(-1, 28*28)\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    outputs_softmax = F.softmax(outputs, dim=1)\n",
        "    predicted = torch.argmax(outputs_softmax, dim=1)\n",
        "\n",
        "    num_total_data += len(images)\n",
        "    answer = sum(labels==predicted).item()\n",
        "    correct += answer\n",
        "\n",
        "print(\"Model accuracy {:.5f}%\".format((correct/num_total_data)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scVxBcwx3-oJ",
        "outputId": "f8475dde-f699-4d62-9bf2-ae4a50e84313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy 96.72000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ppYTgDWs5mqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice 2. Batch nomalization"
      ],
      "metadata": {
        "id": "BGGK6rQG5oQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import package\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.utils.data as data_utils\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "7dtKdvW45sL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU/CPU setting\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0PLRzHK5v1M",
        "outputId": "a22710c0-23e7-4929-a42f-8bc410503cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dataset\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "metadata": {
        "id": "a-_z8Ung50QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch generation\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "HQHN82Fn54_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "\n",
        "class Batch_Norm(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Batch_Norm, self).__init__()\n",
        "\n",
        "    self.network = nn.Sequential(nn.Linear(784, 256),\n",
        "                                 nn.BatchNorm1d(256),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Linear(256, 64),\n",
        "                                 nn.BatchNorm1d(64),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Linear(64, 10))\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.network(x)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "WcIyeCtb5-wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "\n",
        "num_epochs = 10\n",
        "learning_rate = 0.01\n",
        "\n",
        "model = Batch_Norm().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "9DGyNuip6nLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "\n",
        "# Model Train\n",
        "loss_list = []\n",
        "for epoch_num in range(num_epochs):\n",
        "  average_cost = 0\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx, (x_data, y_label) in enumerate(train_loader):\n",
        "    num_of_mini_batch = len(train_loader)\n",
        "\n",
        "    x_data = x_data.reshape(-1, 28*28)\n",
        "    input_image = x_data.to(device)\n",
        "    label = y_label.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    y_predict = model(input_image)\n",
        "    loss = criterion(y_predict, label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    average_cost = average_cost + (loss.item()/num_of_mini_batch)\n",
        "    loss_list.append(loss)\n",
        "\n",
        "  print(\"Epoch {} Loss {:.5f}\".format((epoch_num+1), average_cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqCb2Nez691T",
        "outputId": "748a6770-85f9-4b47-9615-ba4297bd159f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss 0.02289\n",
            "Epoch 2 Loss 0.02098\n",
            "Epoch 3 Loss 0.01763\n",
            "Epoch 4 Loss 0.02005\n",
            "Epoch 5 Loss 0.01910\n",
            "Epoch 6 Loss 0.01423\n",
            "Epoch 7 Loss 0.01579\n",
            "Epoch 8 Loss 0.01666\n",
            "Epoch 9 Loss 0.01383\n",
            "Epoch 10 Loss 0.01254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation\n",
        "\n",
        "with torch.no_grad():\n",
        "  num_total_data = 0\n",
        "  correct = 0\n",
        "  model.eval()\n",
        "  for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "\n",
        "    images = images.reshape(-1, 28*28)\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    outputs_softmax = F.softmax(outputs, dim=1)\n",
        "    predicted = torch.argmax(outputs_softmax, dim=1)\n",
        "\n",
        "    num_total_data += len(images)\n",
        "    answer = sum(labels==predicted).item()\n",
        "    correct += answer\n",
        "\n",
        "print(\"Model accuracy {:.5f}%\".format((correct/num_total_data)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAo7h0YI7GVC",
        "outputId": "07e28515-52c4-4a50-ff3d-ce7147f7b0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy 97.91000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B_soXTG_Ao3g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}